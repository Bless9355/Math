\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{ wasysym }
\usepackage{enumerate}
\usepackage{verbatim}


\numberwithin{equation}{section}
\newcommand{\new}[2]{
    \vspace{2mm}
    \noindent
    \textbf{
    \underline{#1}}
    \textit{{#2}}
    \
}

\def\<{{\langle}}
\def\>{{\rangle}}

\DeclarePairedDelimiter\bra{\langle}{\rvert}
\DeclarePairedDelimiter\ket{\lvert}{\rangle}
\DeclarePairedDelimiterX\braket[2]{\langle}{\rangle}{#1\,\delimsize\vert\,\mathopen{}#2}


\newcommand{\textOr}{
    {
        \hspace{5mm}
        \textrm{or}
        \hspace{5mm}
    }
}

\newcommand{\textAnd}{
    {
        \hspace{5mm}
        \textrm{and}
        \hspace{5mm}
    }
}


\newcommand{\textWhere}{
    {
        \hspace{5mm}
        \textrm{where}
        \hspace{5mm}
    }
}



%Physics related
\newcommand{\Ixp}[1]{
    {
        e^{i{#1}}
    }
}

\newcommand{\ExpVal}[1]{
    {
        \langle{#1}\rangle
    }
}


\newcommand{\InProd}[2]{
    {
        \langle{#1, #2}\rangle
    }
}

\newcommand{\pderiv}[1]{
    {
        \frac {\partial}{\partial{#1}}
    }
}








\newcommand{\halfFigure}[1]{
\begin{center}
\includegraphics[width = .5\linewidth]{{#1}}
\end{center}
}

\newcommand{\fullFigure}[1]{
\begin{center}
\includegraphics[width = .9\linewidth]{{#1}}
\end{center}
}

\def\twobytwoMat(#1, #2, #3, #4){
    {
        \begin{bmatrix}
            {#1} & {#2}\\
            {#3} & {#4}
        \end{bmatrix}
    }
}

\def\twobyoneMat(#1, #2){
    {
        \begin{bmatrix}
            {#1}\\
            {#2}
        \end{bmatrix}
    }
}

\def\twobytwoDet(#1, #2, #3, #4){
    {
        \begin{vmatrix}
            {#1} & {#2}\\
            {#3} & {#4}
        \end{vmatrix}
    }
}


\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\Zpos}{\mathbb{Z}_{pos}}
\newcommand{\NN}{\mathbb{N}}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{conjecture}{Conjecture}
\newtheorem{question}{Question}

\newcommand{\ch}{\text{ch}}

\begin{document}
\begin{center}
    \Large
    \textbf{Report 1.1: Quantum Operators}

    \large
    Daniel Son
\end{center}

\begin{abstract}
    This note is a collection of exercises and solutions on 
    quantum operators in the context of mathematical modeling. 
    The problems were generated by chatGPT after providing the model 
    with Baragrello's textbook as reference. 
\end{abstract}

\section{The Bosonic Number Operator}

\textbf{Problem:}  
Consider a system of \( L \) bosonic modes described by the operators \( a_l \) and \( a_l^\dagger \), satisfying the commutation relations:
\[
[a_l, a_n^\dagger] = \delta_{ln} \mathbb{I}, \quad [a_l, a_n] = [a_l^\dagger, a_n^\dagger] = 0
\]
Show that the number operator \( \hat{N} = \sum_{l=1}^L a_l^\dagger a_l \) is self-adjoint and find its action on the Fock state \( |n_1, n_2, \dots, n_L \rangle \).

\begin{proof}
    The total number operator $\hat N$ can be expressed as a sum of
    number operators for each states. Define 
    \begin{align}
        \hat n_l \ := \ a_l^\dag a_l
    \end{align}
    then, this auxillary number operator for state $l$ recovers the 
    number of particles in state $l$. 

    We first recall how a Fock state is constructed. Given a set of 
    operators $\{a_l, a_l^\dag| 1 \leq l \leq L\}$, there exists a 
    vaccum state $\phi_0$ where $a_l \varphi_0 = 0$ for all $0 \leq l \leq L$. 
    The Fock state $\ket{n_1, \dots, n_L}$ is defined as 
    \begin{align}
        \varphi_{n_1, \dots, n_L} \ := \ \ket{n_1, \dots, n_L} \
        := \  \frac 1 
        {\sqrt{ {n_1! \dots n_L!}}} (a_1^\dag)^{n_1} \cdots (a_L^\dag)^{n_L} \varphi_0
    \end{align}
    The intution behind the construction is that the operators 
    $a_l^\dag$ corresponds to the creation operators, and the $a_l$ 
    to the anhilation operators. Thus, if the Fock state has $n_l$ 
    particles in state $l$, then the state can be recovered from the 
    vaccum state by adding $n_l$ creation operators. The reciprocal 
    of the sqareroot of the factorials ensure that the state is normalized, 
    i.e. $\|\varphi_{n_1, \dots, n_L}\| = \|\varphi_0\| = 1$. 

    We now show that 
    \begin{align}
        \hat n_l \ket{n_1, \dots, n_L} \ =\ n_l \ket{n_1, \dots, n_L}.
    \end{align}
    It suffices to show that 
    \begin{align}
        (a_l^\dag a_l) (a_l^\dag)^{n_l} \varphi_0 \ = \ n_l(a_l^\dag)^{n_l} \varphi_0
    \end{align}
    since each operator corresponding to different states commute. 
    We prove this by induction. For simplicity, we drop the subscripts 
    and write $a, n$ instead of $a_l, n_l$. Induct on $n$. For the 
    base case, 
    \begin{align}
        (a^\dag a) (a^\dag)^0 \varphi_0 \ = \ 0 
    \end{align}
    since the vaccum is anhilated by $a$. For the inductive step, 
    consider the following. 
    \begin{align}
        (a^\dag a) (a^\dag)^n \varphi_0\ = \ 
        a^\dag (a a^\dag) (a^\dag)^{n -1 }\varphi_0 = 
        a^\dag (I + a^\dag a)(a^\dag)^{n -1 } \varphi_0  \\ 
        = \ (a^\dag)^n \varphi_0 + (a^\dag a) (a^\dag)^{n - 1}\varphi_0 
        \ = \ (1 + n - 1) (a^\dag)^n \varphi_0 \ = \ 
        n (a^\dag)^n \varphi_0
        \end{align}
    which proves our claim. 

    The total number operator is sum of all the auxillary operators. 
    That is, 
    \begin{align}
        \hat N  \ = \ 
        \sum_{l = 1}^{L} n_l
    \end{align}
    and thus, the action of the total number operator on a Fock state is 
    \begin{align}
        \hat N \ket{n_1, \dots, n_L} \ = \ 
        \left(\sum_{l = 1}^L n_l\right) \ket{n_1, \dots, n_L}
    \end{align}
    
    
\end{proof}

\section{The Fermionic Number Operator}

\textbf{Problem:}  
For a system of fermionic modes, the creation and annihilation operators \( b_l \) and \( b_l^\dagger \) satisfy the anticommutation relations:
\[
\{b_l, b_n^\dagger\} = \delta_{ln} \mathbb{I}, \quad \{b_l, b_n\} = \{b_l^\dagger, b_n^\dagger\} = 0
\]
Prove that the number operator \( \hat{N} = \sum_{l=1}^L b_l^\dagger b_l \) has eigenvalues 0 and 1 for each mode, and show why this implies the Pauli exclusion principle.

\begin{proof}
    We build on from a similar framework as we did from the Bosonic model. 
    However, the Common Anticomutator Relation(CAR) implies the follwing. 
    \begin{align}
        \{b^\dag_n, b^\dag_n\} \ = \ 2(b^\dag_n)^2 \ = 0 
        \textOr 
        (b^\dag)^2 \ = \  0
    \end{align}
    This implies that for Fauk states that have $n_l > 1$, the 
    state must be identically zero. 

    The pauli exclusion principle states that there cannot be more 
    than one electron in one state, and the CAR implies this principle; 
    if a state had more than one electron in one level, it would be 
    equivalent to the zero state. 
\end{proof}

\section{Schrodinger and Heisenberg representations}
\textbf{Problem:}
Suppose $A$ is an observable
in the quantum system $\mathcal S$. What is the Schrodinger representation 
and the Heisenberg representation of $A$? Derive a relation between the 
two observables. 

\begin{proof}[Solution]
    The Schrodinger representation of the observable is a time independant 
    matrix that describes the observable. From the representation, we can 
    derive the expected value of the observable given a state $\Psi(t)$
    \begin{align}
        \ExpVal{A} \ = \ \InProd{\Psi(t)}{A \Psi(t)}
    \end{align}
    Suppose the time evolution of $\Psi(t)$ is governed by a time 
    evolution operator $U(t)$, i.e. 
    \begin{align}
        \Psi(t) \ = \ U(t) \Psi_0
    \end{align}
    where $\Psi_0$ is the initial state. Then, the expected value 
    of the observable can be rewritten as 
    \begin{align}\label{eqn:Heisenberg}
        \ExpVal{A} \ = \ \InProd{U(t)\Psi_0}{A U(t)\Psi_0} \ = \  
        \InProd{\Psi_0}{U(t)^\dag A U(t) \Psi(0)}
        \ = \  
        \ExpVal{U(t)^\dag A U(t)}_{H} 
    \end{align}
    where the time dependence has been incorporated into the observable, 
    not the state. This new time dependent operator is the 
    \textbf{Heisenberg Representation} of observable $A$. In symbols, 
    \begin{align}
        A(t) \ := \ U(t)^\dag A U(t)
    \end{align}

    Recall the Schrodinger equation. The time derivative operator 
    is govenred by the Hamiltonian. We assume the Hamilonian to be 
    time independent and self-adjoint. 
    \begin{align}
        i \pderiv{t} U(t) \ = \ H(t) U(t) 
        \textAnd
        -i \pderiv{t} U(t)^\dag \ = \ U(t)^\dag H(t)^\dag 
    \end{align}
    Take the time derivative of equation \eqref{eqn:Heisenberg} by 
    invoking the chain rule. 
    \begin{align}
        \pderiv{t} A(t) \ = \  
        \left(
            \pderiv t U(t)^\dag 
        \right) A U(t) + 
        U^\dag(t) A
        \left(
            \pderiv t U(t)
        \right) \nonumber \\ 
        = \ U(t)^\dag \left(iH^\dag A - iA H\right) U(t)
    \end{align}
    Thus, 
    \begin{align}
        \dot A(t) \ = \ [A(t), H(t)]
    \end{align}
    where $H(t)$ is the Heisenberg representation of the Hamiltonian. 

    Also, if the Shrodinger equation is time-dependent, then 
\begin{align}
        \dot A(t) \ = \ [A(t), H(t)] + i \pderiv t A
    \end{align}
\end{proof}

\section*{2.4 Dynamics for a Quantum System: Schrödinger Representation}

\textbf{Problem:}  
Starting from the Schrödinger equation:
\[
i \frac{\partial}{\partial t} \Psi(t) = H(t) \Psi(t)
\]
derive the expression for the unitary time evolution operator \( U(t, t_0) \) when the Hamiltonian \( H(t) \) does not explicitly depend on time. Then, generalize this result for the time-dependent case where \( [H(t_1), H(t_2)] = 0 \) for all \( t_1, t_2 \).

\begin{proof}[Solution]
    First assume that the Hamiltonian is constant. Then, the equation is 
    separable, and we notice that 
    \begin{align}
        i\left(\pderiv{t} \Psi(t) \right)\frac 1 {\Psi(t)} \ = \ H 
    \end{align}
    and by taking the derivative with respect to time both sides, 
    \begin{align}
        \ln\left(
            \Psi(t)
        \right) \ = \  
        -i Ht + \ln(A)
    \end{align}
    and thus, 
    \begin{align}
        \Psi(t) \ = \ A e^{-iHt}
    \end{align}
    where the constant $A$ depends on the initial condition. We know 
    that $\Psi(0)$ is the initial state. Hence, 
    \begin{align}
        \Psi(t) \ = \ e^{-iHt} \Psi(0)
    \end{align}

    Suppose the Hamiltonian varies as a function of time, but the 
    evolution is time independent. That is, for any $t_1,t_2 > 0$, 
    \begin{align}
        [U(t_1), U(t_2)] \ = \ 0.
    \end{align}
    We repeat the process layed below. 
    \begin{align}
        i\left(\pderiv t \Psi(t) \right)\frac 1 {\Psi(t)} & = H(t) \\ 
        \ln(\Psi(t)) - \ln(\Psi(0)) & = -i\int_{0}^t H(u) du \\ 
        \Psi(t) & = \exp\left(
            -i\int_{0}^t H(u) du
        \right)\Psi(0)
    \end{align}
    Based on the integral, it is possible to obtain the commutator 
    of two time evolution operators. 
    \begin{align}
        [U(t_1), U(t_2)] \ =  
        \ \int_{0}^{t_2} \int_0^{t_1} [H(u), H(v)]dv du
    \end{align}
    So if the Hamilonians-which are also Schrodinger representations, 
    and hence a matrix-
    do not commute, then it is not guaranteed that 
    \begin{align}
        U(t_1)U(t_2) \ = \ U(t_2)U(t_1)
    \end{align}
\end{proof}

\section*{2.5 Heisenberg Uncertainty Principle}

\textbf{Problem:}  
Consider two operators \( A \) and \( B \) acting on a Hilbert space \( H \). The uncertainties \( \Delta A \) and \( \Delta B \) are defined as:
\[
(\Delta A)^2 = \langle \psi, (A - \langle A \rangle)^2 \psi \rangle, \quad (\Delta B)^2 = \langle \psi, (B - \langle B \rangle)^2 \psi \rangle
\]
where \( \langle A \rangle = \langle \psi, A \psi \rangle \) and similarly for \( B \). Prove the Heisenberg uncertainty principle:
\[
\Delta A \Delta B \geq \frac{1}{2} | \langle [A, B] \rangle |
\]
where \( [A, B] \) is the commutator of \( A \) and \( B \).

\begin{proof}
    We apply the Cauchy-Schwartz inequality. The inner product 
    of two vectors are less than the product of their respective norms. 
    \begin{align}\label{eqn:CS}
        \InProd{(A^2-\ExpVal{A}^2)\Psi}{(B^2-\ExpVal{B}^2)\Psi} \ \leq  
        \|(A^2-\ExpVal{A}^2)\Psi\|^2 \|(B^2-\ExpVal{B}^2)\Psi\|^2
    \end{align}
    The norm of $(A^2-\ExpVal{A}^2)\Psi$ squared is 
    \begin{align}
        \|(A^2-\ExpVal{A}^2)\Psi\|^2 \ = \ \InProd{(A^2-\ExpVal{A}^2)\Psi}{(A^2-\ExpVal{A}^2)\Psi}
        \ = \ (\Delta A)^4. 
    \end{align}
    Apply the same equation to $B$ and take square root on both sides equation \eqref{eqn:CS}. 
    \begin{align}
        \InProd{(A-\ExpVal{A})\Psi}{(B-\ExpVal{B})\Psi} \ \leq (\Delta A\Delta B)^2 
    \end{align}\footnote{It is straightforward to show that the LHS of this equation squared 
    is the LHS of \eqref{eqn:CS}}
    Concentrate all operators to one side of the norm. 
    \begin{align}
        \InProd{\Psi} {(A - \ExpVal A)(B - \ExpVal B)\Psi} \ \leq 
        (\Delta A \Delta B)^2
    \end{align}
    It is straightforward to verify the follwing equation. 
    \begin{align}
        (A - \ExpVal A)(B - \ExpVal B) \ = \ 
        \frac {
            (A - \ExpVal A)(B - \ExpVal B) + (A - \ExpVal A)(B - \ExpVal B)
        } 2\nonumber \\ +
    \frac {
            (A - \ExpVal A)(B - \ExpVal B) - (A - \ExpVal A)(B - \ExpVal B)
        } 2
    \end{align}
    We call the former operator $F$ and the latter operator $C$. 
    Notice that $C^\dag = -C$ so the operator must be purely imaginary. 
    Taking the expected value of both $F, C$, we verify that 
    \begin{align}
        \ExpVal{(A - \ExpVal A)(B - \ExpVal B)} \ = \  
        \ExpVal{
            \frac 1 2\left(\{A, B\} + i [A, B]\right)
        }
    \end{align}
    Finally, we obtain the Heisenberg inequality by ignoring the anticommutator. 
    \begin{align}
        (\Delta A \Delta B)^2 \ \geq \ 
        |\ExpVal{\frac 1 2\left(\{A, B\} + i [A, B]\right)}|^2 \ \geq \ 
        \frac 1 4 \|\ExpVal{[A, B]}\|^2 \\ 
        \Delta A \Delta B \geq \frac 1 2\|\ExpVal{[A, B]}\|
    \end{align}

\end{proof}

\begin{comment}

\section*{2.6 A Few Words on States}

\textbf{Problem:}  
A state \( \omega \) over a \( \ast \)-algebra \( \mathcal{A} \) satisfies:
\[
\omega(A^\ast A) \geq 0, \quad \omega(1) = 1, \quad \omega(A^\ast) = \omega(A)
\]
for all \( A \in \mathcal{A} \). Consider a vector state \( \omega(A) = \langle \psi, A \psi \rangle \) for a normalized vector \( \psi \in H \). Show that this definition satisfies the properties of a state and prove the equivalence of vector states with states on \( \ast \)-algebras.

\section*{2.7 More on Dynamics}

\textbf{Problem:}  
The time evolution of an observable \( X(t) \) in a closed quantum system is given by the Heisenberg equation:
\[
\frac{dX(t)}{dt} = i [H, X(t)]
\]
where \( H \) is the Hamiltonian. Show that the solution to this equation is given by:
\[
X(t) = e^{iHt} X(0) e^{-iHt}
\]
and explain how this formalism ensures the unitarity of the time evolution in closed quantum systems.

\section*{2.8 The (H, \( \rho \))-Induced Dynamics}

\textbf{Problem:}  
Consider a system \( S \) with a Hamiltonian \( H \) and a rule \( \rho \) that acts on the space of parameters of \( H \), producing a sequence of Hamiltonians \( H^{(k)} \) for each time interval \( [k\tau, (k+1)\tau] \). The dynamics in each interval are given by:
\[
\dot{A}(t) = U^{(k)} A(t), \quad t \in [k\tau, (k+1)\tau]
\]
where \( U^{(k)} \) is determined by the parameters of \( H^{(k)} \). Find the global solution for \( A(t) \) for all \( t \) by gluing together the local solutions for each interval. Discuss how this piecewise dynamics can lead to a nontrivial equilibrium.

\section*{2.9 A Two-Mode System}

\textbf{Problem:}  
Consider a two-mode fermionic system described by the Hamiltonian:
\[
H = \omega_1 a_1^\dagger a_1 + \omega_2 a_2^\dagger a_2 + \lambda (a_1^\dagger a_2 + a_2^\dagger a_1)
\]
where \( \omega_1, \omega_2 \) and \( \lambda \) are real constants. Solve the Heisenberg equations of motion for the annihilation operators \( a_1(t) \) and \( a_2(t) \), and show that the solutions exhibit oscillations between the two modes. Find the frequency of these oscillations.

\end{comment}

\end{document}